---
title: "Social Media and Mental Health"
---

## Motivation and Context

Today more and more people are using social media, compared to just ten years ago social media usage has consistently grown, a trend that has increased particularly drastically during the Wuhan Corona Virus Lockdowns. However during this same time, there is considerable evidence showing that various measures of mental health such as anxiety, self-esteem, and depression have worsened. The notable similarity between two trends provides ample background for the questioning of a potential connection or correlation between the use of social media, and the prevalence of poor mental health.

My background as a stats and probability major inspired me to analyze this through a statistics lens, and so for Math437, I chose to analyze the dataset “Social Media and Mental Health”, which includes variables like time spent on social media, platform preferences, and demographic factors, alongside 12 measures of mental health (Validation sought from social media, and restlessness from lack of use) for my final project. By combining the trends found in this dataset, with context from other similar studies, I hope to better understand, and to expose the connections between social media, and mental health.


```{r}
#| label: do this first
#| echo: false
#| message: false

# change this to the location of your Quarto file containing your project; then delete this comment
here::i_am("ArthurChang437Final/index.qmd")
```

## Main Objective
The primary goal is to analyze specific social media usage patterns, such as time spent online or preferred platforms, and determine the correlation with mental health, through predictors such as low self esteem, time spent doom scrolling(browsing social media without a specific purpose), and distractibility scores self reported in the "Social Media and Mental Health" dataset. Using statistical methods in R, I will analyze the data and see how social media usage may influence mental health, and whether specific factors such as time spent per day, type of social media use, or age have compounding effects.





## Packages Used In This Analysis

```{r}
#| label: load packages
#| message: false
#| warning: false

library(here)
library(readr)
library(dplyr)
library(ggplot2)
library(rsample)
library(skimr)
library(corrplot)
library(naniar)
library(tidyr)
library(stringr)
library(purrr)
library(tidymodels)
library(recipes)
```


| Package | Use |
|-------------------------------|----------------------------------------|
| [here](https://github.com/jennybc/here_here) | to easily load and save data |
| [readr](https://readr.tidyverse.org/) | to import the CSV file data |
| [dplyr](https://dplyr.tidyverse.org/) | to massage and summarize data |
| [rsample](https://rsample.tidymodels.org/) | to split data into training and test sets |
| [ggplot2](https://ggplot2.tidyverse.org/) | to create nice-looking and informative graphs | # For correlation matrix visualization
| [skimr](https://cran.r-project.org/web/packages/skimr/index.html/) | to create summary statistics |
| [corrplot](https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html/) | to visualize correlation matrices |
[Naniar] [tidyr]https://tidyr.tidyverse.org//) | remove missing data |
[Stringr](https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html/) | to create dummy variables from responses. |
[tidyr]https://tidyr.tidyverse.org//) | remove missing data |
[tidymodels]https://tidyr.tidyverse.org//) | to facilitate modeling |

## Data Description
I am using the ‘Social Media and Mental Health’ dataset, compiled by Souvik Ahmed and sourced from Kaggle (https://www.kaggle.com/datasets/souvikahmed071/social-media-and-mental-health?select=smmh.csv),. The dataset was acquired through an online survey, likely administered via Google Forms, and distributed via fliers at the University of Liberal Arts Bangladesh (ULAB) in Dhaka.

Comprising 481 observations and 21 columns, the dataset includes seven predictor variables—age, gender, occupation, organizational affiliation, frequency of social media use, types of social media platforms used, and average daily time spent—and twelve response variables: frequency of aimless social media use (“doom scrolling”), restlessness when not using social media, ease of distraction, level of worry, difficulty concentrating, frequency of comparing oneself to successful people, feelings about these comparisons, frequency of seeking validation from social media, depression levels, fluctuations in interest in daily activities, sleep issues, and self-esteem.

```{r}
#| label: import data
#| warning: false
smmh_data <- read_csv("smmh.csv")

```

### Data Limitations

The survey’s distribution lacks detailed documentation on collection methods or selection, potentially allowing potential selection bias. Furthermore this distribution may over-represent ULAB students, people who already use the internet more, or college students, limiting the sample’s representativeness for broader populations.
Self-reported data, including predictor variables and response variables , are susceptible to recall bias and social desirability bias, where respondents may under- or over-report behaviors or symptoms. Notably, the dataset, likely collected 2022 in Bangladesh, reflects a snapshot of one time and place and so factors such as social media access, mental health stigma, or heightened usage may reduce its applicability to other regions or time periods.
Additionally, non-standard variables like frequency of aimless social media use and ease of distraction rely on subjective survey questions, which may not align with professional mental health measures. These variables may require interpretation, introducing potential human error or bias. The absence of information on survey oversight, complicates the assessment of data quality and generalizability, meaning the findings in the study should be taken with a grain of salt.

## Data Wrangling (Optional Section)

```{r}
# Clear any lingering variables
rm(list = ls())

# Set seed for reproducibility
set.seed(69)

# 1. Import and inspect the dataset
cat("Step 1: Importing data\n")
smmh_data <- read_csv("smmh.csv")

# Verify column names
cat("Column names in smmh_data:\n")
print(colnames(smmh_data))

# Inspect structure
cat("Structure of smmh_data:\n")
glimpse(smmh_data)

# Summarize missing values
cat("Missing value summary:\n")
miss_summary <- miss_var_summary(smmh_data)
print(miss_summary)

# 2. Handle missing values (target key predictors)
cat("Step 2: Handling missing values\n")
smmh_clean <- smmh_data %>%
  drop_na(
    `1. What is your age?`,
    `2. Gender`,
    `4. Occupation Status`,
    `5. What type of organizations are you affiliated with?`,
    `6. Do you use social media?`,
    `7. What social media platforms do you commonly use?`,
    `8. What is the average time you spend on social media every day?`,
    `9. How often do you find yourself using Social media without a specific purpose?`
  )

# Check if smmh_clean has rows
cat("Rows in smmh_clean after drop_na():", nrow(smmh_clean), "\n")
if (nrow(smmh_clean) == 0) {
  stop("Error: smmh_clean has no rows after drop_na(). Check missing data in key predictors.")
}

# 3. Rename columns, recode variables, and create dummy variables
cat("Step 3: Transforming data\n")

# Define platform name corrections
platform_corrections <- c(
  "redit" = "reddit",
  "instgram" = "instagram",
  "facebok" = "facebook",
  "twiter" = "twitter"
)

# Extract and clean unique platforms
cat("Extracting unique platforms\n")
unique_platforms <- smmh_clean %>%
  pull(`7. What social media platforms do you commonly use?`) %>%
  na.omit() %>%
  str_split(",\\s*") %>%
  unlist() %>%
  str_to_lower() %>%
  str_trim() %>%
  recode(!!!platform_corrections) %>%
  unique()

cat("Unique platforms identified:", unique_platforms, "\n")
if (length(unique_platforms) == 0) {
  stop("Error: No unique platforms identified. Check platform column data.")
}


cat("Renaming columns\n")
smmh_clean <- smmh_clean %>%
  rename(
    timestamp = `Timestamp`,
    age = `1. What is your age?`,
    gender = `2. Gender`,
    relationship_status = `3. Relationship Status`,
    occupation = `4. Occupation Status`,
    affiliation = `5. What type of organizations are you affiliated with?`,
    use_social_media = `6. Do you use social media?`,
    time_spent = `8. What is the average time you spend on social media every day?`,
    doom_scrolling = `9. How often do you find yourself using Social media without a specific purpose?`,
    distraction_busy = `10. How often do you get distracted by Social media when you are busy doing something?`,
    restlessness = `11. Do you feel restless if you haven't used Social media in a while?`,
    distractibility = `12. On a scale of 1 to 5, how easily distracted are you?`,
    worry = `13. On a scale of 1 to 5, how much are you bothered by worries?`,
    concentration_difficulty = `14. Do you find it difficult to concentrate on things?`,
    comparison_freq = `15. On a scale of 1-5, how often do you compare yourself to other successful people through the use of social media?`,
    comparison_feel = `16. Following the previous question, how do you feel about these comparisons, generally speaking?`,
    validation = `17. How often do you look to seek validation from features of social media?`,
    depression = `18. How often do you feel depressed or down?`,
    interest_fluctuation = `19. On a scale of 1 to 5, how frequently does your interest in daily activities fluctuate?`,
    sleep_issues = `20. On a scale of 1 to 5, how often do you face issues regarding sleep?`
  )

cat("Columns after renaming:", colnames(smmh_clean), "\n")

cat("Creating cleaned_platforms column\n")
smmh_clean <- smmh_clean %>%
  mutate(
    cleaned_platforms = str_to_lower(str_trim(`7. What social media platforms do you commonly use?`)) %>%
      recode(!!!platform_corrections)
  )

cat("Head of cleaned_platforms:\n")
print(head(smmh_clean$cleaned_platforms))
if (all(is.na(smmh_clean$cleaned_platforms))) {
  stop("Error: cleaned_platforms contains only NA values. Check platform column data.")
}

cat("Creating platform dummy variables\n")
# Test dummy variable creation independently
```


```{r}
# Debug dummy variable creation
cat("Debugging dummy variable creation\n")
cat("Unique platforms length:", length(unique_platforms), "\n")
cat("Unique platforms:", unique_platforms, "\n")
cat("Head of cleaned_platforms:\n")
print(head(smmh_clean$cleaned_platforms))

# Check inputs
if (length(unique_platforms) == 0) {
  stop("Error: unique_platforms is empty. Check platform column data.")
}
if (all(is.na(smmh_clean$cleaned_platforms))) {
  stop("Error: cleaned_platforms contains only NA values. Check platform column data.")
}

# Create dummy variables
cat("Creating platform dummy variables\n")

# Safely generate dummy variable columns as a dataframe
dummy_df <- map_dfc(unique_platforms, function(platform) {
  result <- as.integer(str_detect(smmh_clean$cleaned_platforms, platform))
  cat("Dummy variable for", platform, "- first few values:", head(result), "\n")
  tibble(!!paste0("platform_", make.names(platform)) := result)
})

# Bind to the main dataframe
smmh_clean <- bind_cols(smmh_clean, dummy_df)

```

```{r}
# No need to recreate dummy_df or bind it again — it's already done.

cat("Columns after dummy variables:", colnames(smmh_clean), "\n")

# Recode other variables
cat("Recoding other variables\n")
smmh_clean <- smmh_clean %>%
  mutate(
    use_social_media = case_when(
      use_social_media == "Yes" ~ 1,
      use_social_media == "No" ~ 0,
      TRUE ~ NA_real_
    ),
    gender = case_when(
      gender == "Male" ~ 1,
      gender == "Female" ~ 2,
      TRUE ~ 3  # Any other gender, including "Non-binary" or missing
    ),
    time_spent = case_when(
      time_spent == "Less than an Hour" ~ 0.5,
      time_spent == "Between 1 and 2 hours" ~ 1.5,
      time_spent == "Between 2 and 3 hours" ~ 2.5,
      time_spent == "Between 3 and 4 hours" ~ 3.5,
      time_spent == "Between 4 and 5 hours" ~ 4.5,
      time_spent == "More than 5 hours" ~ 6,
      TRUE ~ NA_real_
    ),
    relationship_status = case_when(
      relationship_status == "Single" ~ 1,
      relationship_status == "In a relationship" ~ 2,
      relationship_status == "Married" ~ 3,
      TRUE ~ 4  # For other or NA
    ),
    occupation = as.factor(occupation),
    affiliation = as.factor(affiliation)
  ) %>%
  select(-cleaned_platforms)  # Remove temporary platform column

cat("Columns after recoding:", colnames(smmh_clean), "\n")


```
## Exploratory Data Analysis
```{r}
set.seed(69)

# 1. Summary Statistics of Key Variables
cat("Step 1: Summary Statistics of Social Media and Mental Health Variables\n")
# Select key predictors (time spent, platforms) and mental health outcomes
key_vars <- smmh_clean %>%
  select(
    time_spent, platform_facebook, platform_reddit, platform_discord,
    depression, worry, concentration_difficulty, restlessness, comparison_freq,
    # Supporting variables for context
    age, gender, occupation, affiliation
  )

# Generate summary statistics
skim_result <- skim(key_vars)
print(skim_result)

# 2. Platform Usage Summary
cat("Step 2: Proportion of Users by Social Media Platform\n")
# Summarize platform usage
platform_usage <- smmh_clean %>%
  select(platform_facebook, platform_reddit, platform_discord) %>%
  summarise_all(mean, na.rm = TRUE) %>%
  pivot_longer(everything(), names_to = "platform", values_to = "proportion") %>%
  mutate(platform = gsub("platform_", "", platform))

# Bar plot of platform usage
platform_bar <- ggplot(platform_usage, aes(x = reorder(platform, proportion), y = proportion, fill = platform)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(title = "Proportion of Users by Social Media Platform", x = "Platform", y = "Proportion of Users") +
  scale_fill_manual(values = c("facebook" = "blue", "reddit" = "orange", "discord" = "purple")) +
  theme_minimal()
print(platform_bar)

# 3. Time Spent on Social Media Distribution
cat("Step 3: Distribution of Time Spent on Social Media\n")
# Bar plot of time spent
time_spent_bar <- ggplot(smmh_clean, aes(x = factor(time_spent))) +
  geom_bar(fill = "lightgreen", color = "black") +
  labs(title = "Distribution of Time Spent on Social Media", x = "Hours per Day", y = "Count") +
  theme_minimal() +
  scale_x_discrete(labels = c("0.5" = "<1", "1.5" = "1-2", "2.5" = "2-3", "3.5" = "3-4", "4.5" = "4-5", "6" = ">5"))
print(time_spent_bar)

# 4. Mental Health Outcomes by Platform
cat("Step 4: Mental Health Outcomes by Social Media Platform\n")
# Box plots for mental health outcomes by platform (Facebook, Reddit, Discord)
mental_health_by_platform <- smmh_clean %>%
  select(
    platform_facebook, platform_reddit, platform_discord,
    depression, worry, concentration_difficulty, restlessness, comparison_freq
  ) %>%
  pivot_longer(
    cols = c(depression, worry, concentration_difficulty, restlessness, comparison_freq),
    names_to = "outcome",
    values_to = "score"
  ) %>%
  pivot_longer(
    cols = starts_with("platform_"),
    names_to = "platform",
    values_to = "uses_platform",
    values_drop_na = TRUE
  ) %>%
  mutate(platform = gsub("platform_", "", platform))

# Box plot of mental health outcomes by platform usage
platform_outcome_box <- ggplot(mental_health_by_platform, aes(x = factor(uses_platform), y = score, fill = factor(uses_platform))) +
  geom_boxplot() +
  facet_grid(outcome ~ platform, scales = "free_y") +
  labs(title = "Mental Health Outcomes by Platform Usage",
       x = "Uses Platform (0 = No, 1 = Yes)", y = "Score (1-5)") +
  scale_fill_manual(values = c("0" = "lightblue", "1" = "pink")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(platform_outcome_box)

# 5. Time Spent vs. Mental Health Outcomes
cat("Step 5: Time Spent vs. Mental Health Outcomes\n")
# Scatter plots for time spent vs. mental health outcomes
mental_health_time <- smmh_clean %>%
  select(time_spent, depression, worry, concentration_difficulty, restlessness, comparison_freq) %>%
  pivot_longer(
    cols = c(depression, worry, concentration_difficulty, restlessness, comparison_freq),
    names_to = "outcome",
    values_to = "score"
  )

# Scatter plot with regression line
time_outcome_scatter <- ggplot(mental_health_time, aes(x = time_spent, y = score)) +
  geom_point(color = "blue", alpha = 0.5) +
  geom_smooth(method = "lm", color = "red") +
  facet_wrap(~ outcome, scales = "free_y") +
  labs(title = "Time Spent on Social Media vs. Mental Health Outcomes",
       x = "Time Spent (Hours)", y = "Score (1-5)") +
  theme_minimal()
print(time_outcome_scatter)

# 6. Correlation Analysis
cat("Step 6: Correlation Between Social Media Use and Mental Health\n")
# Select variables for correlation
cor_vars <- smmh_clean %>%
  select(
    time_spent, platform_facebook, platform_reddit, platform_discord,
    depression, worry, concentration_difficulty, restlessness, comparison_freq,
    age  # Include age as supporting variable
  )

# Compute correlation matrix
cor_matrix <- cor(cor_vars, use = "complete.obs")

# Visualize correlation matrix
corrplot(cor_matrix, method = "color", type = "upper", tl.col = "black", tl.srt = 45,
         addCoef.col = "black", number.cex = 0.6, title = "Correlation Matrix: Social Media and Mental Health")

# 7. Supporting Variable: Age vs. Mental Health Outcomes
cat("Step 7: Age vs. Mental Health Outcomes (Supporting Analysis)\n")
# Scatter plot: Age vs. Mental Health Outcomes
age_mental_health <- smmh_clean %>%
  select(age, depression, worry, concentration_difficulty, restlessness, comparison_freq) %>%
  pivot_longer(
    cols = c(depression, worry, concentration_difficulty, restlessness, comparison_freq),
    names_to = "outcome",
    values_to = "score"
  )

age_outcome_scatter <- ggplot(age_mental_health, aes(x = age, y = score)) +
  geom_point(color = "green", alpha = 0.5) +
  geom_smooth(method = "lm", color = "red") +
  facet_wrap(~ outcome, scales = "free_y") +
  labs(title = "Age vs. Mental Health Outcomes (Supporting Analysis)",
       x = "Age", y = "Score (1-5)") +
  theme_minimal()
print(age_outcome_scatter)
```

## Modeling
```{r}
# Set seed for reproducibility
set.seed(69)

# 1. Data Preparation
cat("Step 1: Preparing Data for Modeling\n")

# Select relevant variables for modeling
model_data <- smmh_clean %>%
  select(
    time_spent, platform_facebook, platform_reddit, platform_discord,
    depression, worry, concentration_difficulty, restlessness, comparison_freq,
    age, gender, occupation, affiliation
  ) %>%
  # Ensure no missing values in predictors and outcomes
  drop_na(time_spent, platform_facebook, platform_reddit, platform_discord, age, gender, occupation, affiliation,
          depression, worry, concentration_difficulty, restlessness, comparison_freq)

# Check if data is sufficient
cat("Rows in model_data:", nrow(model_data), "\n")
if (nrow(model_data) == 0) {
  stop("Error: model_data has no rows after drop_na(). Check missing data.")
}

# Verify platform variables exist
cat("Available columns:", colnames(model_data), "\n")
if (!all(c("platform_facebook", "platform_reddit", "platform_discord") %in% colnames(model_data))) {
  stop("Error: One or more platform variables (platform_facebook, platform_reddit, platform_discord) are missing. Check data wrangling.")
}

# Split data into training (70%) and testing (30%) sets
data_split <- initial_split(model_data, prop = 0.7, strata = depression)
train_data <- training(data_split)
test_data <- testing(data_split)

cat("Training set rows:", nrow(train_data), "\n")
cat("Testing set rows:", nrow(test_data), "\n")

# Define mental health outcomes to model
outcomes <- c("depression", "worry", "concentration_difficulty", "restlessness", "comparison_freq")

# 2. Modeling Function
cat("Step 2: Defining Modeling Function\n")

# Function to fit and evaluate models for a given outcome
fit_and_evaluate <- function(outcome) {
  cat("\nModeling for outcome:", outcome, "\n")
  
  # Verify outcome exists in test_data
  if (!outcome %in% colnames(test_data)) {
    stop("Error: Outcome ", outcome, " not found in test_data.")
  }
  
  # Create recipe for preprocessing
  model_recipe <- recipe(as.formula(paste(outcome, "~ time_spent + platform_facebook + platform_reddit + platform_discord + age + gender + occupation + affiliation")), 
                         data = train_data) %>%
    step_dummy(all_nominal_predictors()) %>%           # Convert categorical variables to dummy variables
    step_zv(all_predictors()) %>%                     # Remove zero-variance predictors
    step_corr(all_numeric_predictors(), threshold = 0.9) %>%  # Remove highly correlated predictors
    step_normalize(all_numeric_predictors())          # Normalize numeric predictors
  
  # Define models
  # Linear Regression
  lm_spec <- linear_reg() %>%
    set_engine("lm")
  
  # KNN
  knn_spec <- nearest_neighbor(neighbors = tune()) %>%
    set_engine("kknn") %>%
    set_mode("regression")
  
  # Regression Tree
  tree_spec <- decision_tree(tree_depth = tune(), min_n = tune()) %>%
    set_engine("rpart") %>%
    set_mode("regression")
  
  # Create workflows
  lm_workflow <- workflow() %>%
    add_recipe(model_recipe) %>%
    add_model(lm_spec)
  
  knn_workflow <- workflow() %>%
    add_recipe(model_recipe) %>%
    add_model(knn_spec)
  
  tree_workflow <- workflow() %>%
    add_recipe(model_recipe) %>%
    add_model(tree_spec)
  
  # Cross-validation
  cv_folds <- vfold_cv(train_data, v = 5)
  
  # Tune KNN
  knn_grid <- grid_regular(
    neighbors(range = c(3, 15)),
    levels = 3
  )
  
  knn_tune <- tune_grid(
    knn_workflow,
    resamples = cv_folds,
    grid = knn_grid,
    metrics = metric_set(rmse, rsq)
  )
  
  # Tune Regression Tree
  tree_grid <- grid_regular(
    tree_depth(range = c(3, 10)),
    min_n(range = c(5, 20)),
    levels=3
  )
  
  tree_tune <- tune_grid(
    tree_workflow,
    resamples = cv_folds,
    grid = tree_grid,
    metrics = metric_set(rmse, rsq)
  )
  
  # Fit Linear Regression (no tuning needed)
  lm_fit <- fit(lm_workflow, train_data)
  
  # Select best KNN and Tree models
  best_knn <- finalize_workflow(knn_workflow, select_best(knn_tune, metric = "rmse")) %>%
    fit(train_data)
  
  best_tree <- finalize_workflow(tree_workflow, select_best(tree_tune, metric = "rmse")) %>%
    fit(train_data)
  
  # Evaluate on test set
  test_predictions <- bind_rows(
    tibble(
      .pred = predict(lm_fit, test_data)$.pred,
      model = "Linear Regression",
      actual = test_data[[outcome]]
    ),
    tibble(
      .pred = predict(best_knn, test_data)$.pred,
      model = "KNN",
      actual = test_data[[outcome]]
    ),
    tibble(
      .pred = predict(best_tree, test_data)$.pred,
      model = "Regression Tree",
      actual = test_data[[outcome]]
    )
  )
  
  # Calculate performance metrics
  metrics <- test_predictions %>%
    group_by(model) %>%
    summarise(
      RMSE = sqrt(mean((.pred - actual)^2)),
      Rsq = cor(.pred, actual)^2
    )
  
  cat("Performance metrics for", outcome, ":\n")
  print(metrics)
  
  # Visualize predictions vs. actual
  pred_plot <- ggplot(test_predictions, aes(x = actual, y = .pred, color = model)) +
    geom_point(alpha = 0.5) +
    geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
    facet_wrap(~ model) +
    labs(title = paste("Predictions vs. Actual for", outcome),
         x = "Actual Score", y = "Predicted Score") +
    theme_minimal()
  print(pred_plot)
  
  return(list(metrics = metrics, predictions = test_predictions))
}

# 3. Fit Models for All Outcomes
cat("Step 3: Fitting Models for All Outcomes\n")
results <- map(outcomes, fit_and_evaluate)

# 4. Summarize Results
cat("Step 4: Summarizing Results Across Outcomes\n")
all_metrics <- map_dfr(seq_along(outcomes), function(i) {
  results[[i]]$metrics %>%
    mutate(outcome = outcomes[i])
}) %>%
  select(outcome, model, RMSE, Rsq)

cat("Summary of Model Performance:\n")
print(all_metrics)

# Visualize overall performance
performance_plot <- ggplot(all_metrics, aes(x = outcome, y = RMSE, fill = model)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Model Performance (RMSE) Across Outcomes",
       x = "Mental Health Outcome", y = "RMSE") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(performance_plot)
```


## Insights
Platform Usage Patterns: The EDA showed that Facebook was the most commonly used platform, with approximately 8 in ten people using it , followed by Discord with 4 in ten  and Reddit with 3 in ten. This suggests a preference for Facebook, potentially due to its widespread availability and social networking features, while Discord’s lower usage may reflect its niche appeal among younger or tech-savvy respondents.
Time Spent on Social Media: The distribution of time spent on social media indicated that most respondents spent More than 5 hours per day, but a median of 2 to three hours, the portion exceeding 5 hours daily around 25 percent. This heavy usage indicates there is enough saturation to determine if there is a correlation.
Mental Health Correlations: Scatter plots and correlation analysis revealed a weak positive correlation between negative mental health outcomes between time spent on social media and mental health outcomes. For instance, time spent was moderately correlated with depression suggesting that increased usage may exacerbate these symptoms. 
Model Performance: The modeling phase evaluated Linear Regression, KNN, and Regression Trees for predicting five mental health outcomes (depression, worry, concentration difficulty, restlessness, comparison frequency) using predictors like time_spent, platform_facebook, platform_reddit, platform_discord, age, gender, occupation, and affiliation.
Linear Regression: Achieved an RMSE of 1.374, indicating medium to weak] predictive power. This model performed best for restlessness,but was similar throughout.
KNN: Recorded an RMSE of 1.49, performing better for restlessness due to a particularly strong relation in restlessness
Regression Trees: Yielded an RMSE of 1.46, with weak and roughly equal rmse throughout.
Overall, our model showed the lowest RMSE for Linear regression, suggesting it best captures the relationship between social media usage and mental health for this dataset.
These findings suggest that time spent on social media is a stronger predictor of mental health outcomes than platform type, with potentially amplifying effects like comparison frequency. The models supported some of these relationships, though accuracy is fairly weak due in part to human perception and variability of such.


### Limitations and Future Work
This dataset was both a snapshot, regionally located, and had a relatively small size combined with a fairly small scope and self reported metrics. These make it harder to track the the change over time, whether the trends seen in the  scope exists beyond it and whether this is a trend that persisted over time. For future work I would recommend collecting more data and expirements of large samples of people who dont vs do use social media, though this may be difficult to do considering its near ubiquity in everyday life.

### Reflection (Optional Subsection)
